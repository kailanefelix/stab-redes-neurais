{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28053,
     "status": "ok",
     "timestamp": 1709998928500,
     "user": {
      "displayName": "No Name",
      "userId": "0001"
     },
     "user_tz": -120
    },
    "id": "UOml-K2X3pcU",
    "outputId": "6dd684b4-c90d-48f1-a350-1b36dc5e7e77"
   },
   "outputs": [],
   "source": [
    "# Sistema e utilitários\n",
    "import os\n",
    "import gc\n",
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "\n",
    "# Instalações de pacotes\n",
    "!pip install keras4torch\n",
    "!pip install einops\n",
    "\n",
    "# Bibliotecas principais\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Keras4Torch\n",
    "import keras4torch\n",
    "from keras4torch.callbacks import ModelCheckpoint, LRScheduler\n",
    "\n",
    "# STab\n",
    "import STab\n",
    "from STab import *\n",
    "from STab import mainmodel, LWTA, Gsoftmax\n",
    "\n",
    "# Definição principal do modelo\n",
    "MainModel = mainmodel.MainModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105 samples, validate on 22 samples:\n",
      "Epoch 1/15 - 3.8s - loss: 1.0388 - acc: 0.4571 - val_loss: 0.8196 - val_acc: 0.8636 - lr: 1e-03\n",
      "Epoch 2/15 - 4.3s - loss: 0.7929 - acc: 0.7143 - val_loss: 0.6566 - val_acc: 0.9091 - lr: 1e-03\n",
      "Epoch 3/15 - 3.2s - loss: 0.6391 - acc: 0.7810 - val_loss: 0.4962 - val_acc: 0.9545 - lr: 1e-03\n",
      "Epoch 4/15 - 2.9s - loss: 0.5491 - acc: 0.8762 - val_loss: 0.4416 - val_acc: 0.9545 - lr: 1e-03\n",
      "Epoch 5/15 - 2.6s - loss: 0.4763 - acc: 0.8476 - val_loss: 0.3947 - val_acc: 0.9545 - lr: 1e-03\n",
      "Epoch 6/15 - 2.6s - loss: 0.4328 - acc: 0.8571 - val_loss: 0.3571 - val_acc: 0.9091 - lr: 1e-03\n",
      "Epoch 7/15 - 2.5s - loss: 0.4867 - acc: 0.8286 - val_loss: 0.2750 - val_acc: 1.0000 - lr: 1e-03\n",
      "Epoch 8/15 - 2.5s - loss: 0.3985 - acc: 0.8571 - val_loss: 0.2557 - val_acc: 1.0000 - lr: 1e-03\n",
      "Epoch 9/15 - 2.4s - loss: 0.4345 - acc: 0.8667 - val_loss: 0.2295 - val_acc: 0.9545 - lr: 1e-03\n",
      "Epoch 10/15 - 2.5s - loss: 0.3428 - acc: 0.9048 - val_loss: 0.2207 - val_acc: 1.0000 - lr: 1e-03\n",
      "Epoch 11/15 - 2.4s - loss: 0.3554 - acc: 0.9048 - val_loss: 0.1817 - val_acc: 1.0000 - lr: 1e-03\n",
      "Epoch 12/15 - 2.5s - loss: 0.3567 - acc: 0.8762 - val_loss: 0.1598 - val_acc: 1.0000 - lr: 1e-03\n",
      "Epoch 13/15 - 2.5s - loss: 0.2941 - acc: 0.9048 - val_loss: 0.1511 - val_acc: 1.0000 - lr: 1e-03\n",
      "Epoch 14/15 - 2.4s - loss: 0.2921 - acc: 0.9143 - val_loss: 0.1467 - val_acc: 1.0000 - lr: 1e-03\n",
      "Epoch 15/15 - 2.5s - loss: 0.2844 - acc: 0.8952 - val_loss: 0.1334 - val_acc: 1.0000 - lr: 1e-03\n",
      "Test Accuracy: 0.9130\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00         6\n",
      "  versicolor       1.00      0.80      0.89        10\n",
      "   virginica       0.78      1.00      0.88         7\n",
      "\n",
      "    accuracy                           0.91        23\n",
      "   macro avg       0.93      0.93      0.92        23\n",
      "weighted avg       0.93      0.91      0.91        23\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Carregar Iris\n",
    "iris = load_iris()\n",
    "X = iris.data  # Apenas variáveis numéricas\n",
    "y = iris.target\n",
    "\n",
    "# Dividir em treino, validação e teste\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Normalizar\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train).astype(np.float32)\n",
    "X_valid = scaler.transform(X_valid).astype(np.float32)\n",
    "X_test  = scaler.transform(X_test).astype(np.float32)\n",
    "\n",
    "# Ajustar rótulos para PyTorch\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_valid = torch.tensor(y_valid, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Definir o modelo (sem categorias)\n",
    "Or_model = mainmodel.MainModel(\n",
    "    categories        = (),   # Sem features categóricas\n",
    "    num_continuous    = 4,\n",
    "    dim               = 16,\n",
    "    dim_out           = 3,    # 3 classes (Iris)\n",
    "    depth             = 2,\n",
    "    heads             = 4,\n",
    "    attn_dropout      = 0.1,\n",
    "    ff_dropout        = 0.1,\n",
    "    U                 = 2,\n",
    "    cases             = 8,\n",
    ")\n",
    "\n",
    "# Criar o wrapper Num_Cat para gerenciar as entradas corretamente\n",
    "no_model = Num_Cat(Or_model, num_number=4, classes=3, Sample_size=16)  # 4 features numéricas, 3 classes (Iris)\n",
    "\n",
    "# Passar o modelo para keras4torch\n",
    "model = keras4torch.Model(no_model).build([4])  # Agora só precisa da dimensão numérica\n",
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "model.compile(optimizer=optimizer, loss=F.cross_entropy, metrics=['accuracy'])\n",
    "\n",
    "# Treinamento (passando apenas X numérico)\n",
    "model.fit([X_train], y_train,  # Ajuste aqui: lista com X_train\n",
    "          epochs=15, batch_size=16,\n",
    "          validation_data=([X_valid], y_valid),  # Ajuste aqui\n",
    "          verbose=2)\n",
    "\n",
    "# Avaliação\n",
    "test_logits = model.predict([X_test])  # Passar X_test como lista\n",
    "test_preds = np.argmax(test_logits, axis=1)\n",
    "accuracy = np.mean(test_preds == y_test.numpy())\n",
    "print(f'Test Accuracy: {accuracy:.4f}')\n",
    "\n",
    "report = classification_report(y_test.numpy(), test_preds, target_names=iris.target_names)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
